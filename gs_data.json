{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "9YcR_ksAAAAJ&hl=zh-CN", "source": "AUTHOR_PROFILE_PAGE", "name": "Shangdong Yang", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=9YcR_ksAAAAJ&citpid=4", "affiliation": "Nanjing University of Posts and Telecommunications", "organization": 16347907618724258091, "interests": ["Reinforcement Learning", "Multi-agent Systems", "Multi-armed Bandits"], "email_domain": "@-", "homepage": "http://shangdongyang.github.io/", "citedby": 159, "publications": {"9YcR_ksAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Efficient Average Reward Reinforcement Learning Using Constant Shifting Values", "pub_year": "2016"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:9yKSN-GCB0IC", "num_citations": 38, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=9386619311376424945", "cites_id": ["9386619311376424945"]}, "9YcR_ksAAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "An Optimal Algorithm for the Stochastic Bandits While Knowing the Near-Optimal Mean Reward", "pub_year": "2021"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:2osOgNQ5qMEC", "num_citations": 15, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=9576727640701614028", "cites_id": ["9576727640701614028"]}, "9YcR_ksAAAAJ:W7OEmFMy1HYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "New Galois Hulls Of Generalized Reed-Solomon Codes", "pub_year": "2022"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:W7OEmFMy1HYC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=5569838247276561075", "cites_id": ["5569838247276561075"]}, "9YcR_ksAAAAJ:zYLM7Y9cAGgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A Contextual Bandit Approach to Personalized Online Recommendation via Sparse Interactions", "pub_year": "2019"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:zYLM7Y9cAGgC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=6312536593384931165", "cites_id": ["6312536593384931165"]}, "9YcR_ksAAAAJ:ufrVoPGSRksC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning Explicit Credit Assignment for Cooperative Multi-Agent Reinforcement Learning via Polarization Policy Gradient", "pub_year": "2023"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:ufrVoPGSRksC", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=15393218010128421234", "cites_id": ["15393218010128421234"]}, "9YcR_ksAAAAJ:IjCSPb-OGe4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Contextual Bandits With Hidden Features to Online Recommendation via Sparse Interactions", "pub_year": "2020"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:IjCSPb-OGe4C", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=10774291195010382442", "cites_id": ["10774291195010382442"]}, "9YcR_ksAAAAJ:ULOm3_A8WrAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning Multi-Intersection Traffic Signal Control via Coevolutionary Multi-Agent Reinforcement Learning", "pub_year": "2024"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:ULOm3_A8WrAC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=12751077651211153334", "cites_id": ["12751077651211153334"]}, "9YcR_ksAAAAJ:Se3iqnhoufwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Effective Interpretable Policy Distillation via Critical Experiences Identification", "pub_year": "2023"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:Se3iqnhoufwC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=12436499820390690507", "cites_id": ["12436499820390690507"]}, "9YcR_ksAAAAJ:4DMP91E08xMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Coordinating Multi-Agent Reinforcement Learning via Dual Collaborative Constraints", "pub_year": "2025"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:4DMP91E08xMC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=4472125186392982268", "cites_id": ["4472125186392982268"]}, "9YcR_ksAAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Incremental Nonnegative Matrix Factorization Based on Matrix Sketching and k-means Clustering", "pub_year": "2016"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:qjMakFHDy7sC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=10214692625109174589", "cites_id": ["10214692625109174589"]}, "9YcR_ksAAAAJ:KlAtU1dfN6UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Egoism, Utilitarianism and Egalitarianism in Multi-Agent Reinforcement Learning", "pub_year": "2024"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:KlAtU1dfN6UC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=13282652700691627936", "cites_id": ["13282652700691627936"]}, "9YcR_ksAAAAJ:8k81kl-MbHgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Online Attentive Kernel-based Temporal Difference Learning", "pub_year": "2023"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:8k81kl-MbHgC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=7260461092683050757", "cites_id": ["7260461092683050757"]}, "9YcR_ksAAAAJ:MXK_kJrjxJIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "WToE: Learning When to Explore in Multi-Agent Reinforcement Learning", "pub_year": "2023"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:MXK_kJrjxJIC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=10412989102613807175", "cites_id": ["10412989102613807175"]}, "9YcR_ksAAAAJ:hqOjcs7Dif8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Modified Retrace for Off-Policy Temporal Difference Learning", "pub_year": "2023"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:hqOjcs7Dif8C", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=622156292532045679", "cites_id": ["622156292532045679"]}, "9YcR_ksAAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Modeling rationality: Toward better performance against unknown agents in sequential games", "pub_year": "2022"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:eQOLeE2rZwMC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=14890805184561828596", "cites_id": ["14890805184561828596"]}, "9YcR_ksAAAAJ:aqlVkmm33-oC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multi-Task Multi-Agent Reinforcement Learning With Interaction and Task Representations", "pub_year": "2024"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:aqlVkmm33-oC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=13730792486442168200", "cites_id": ["13730792486442168200"]}, "9YcR_ksAAAAJ:5nxA0vEk-isC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Enhancing OOD Generalization in Offline Reinforcement Learning with Energy-Based Policy Optimization", "pub_year": "2023"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:5nxA0vEk-isC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=11746347888086643694", "cites_id": ["11746347888086643694"]}, "9YcR_ksAAAAJ:Zph67rFs4hoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Decentralized Counterfactual Value with Threat Detection for Multi-Agent Reinforcement Learning in Mixed Cooperative and Competitive Environments", "pub_year": "2024"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:Zph67rFs4hoC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=989565223044549749", "cites_id": ["989565223044549749"]}, "9YcR_ksAAAAJ:YsMSGLbcyi4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Keeping Minimal Experience to Achieve Efficient Interpretable Policy Distillation", "pub_year": "2022"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:YsMSGLbcyi4C", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=8846892003711127496", "cites_id": ["8846892003711127496"]}, "9YcR_ksAAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "An Optimal Algorithm for the Stochastic Bandits with Knowing Near-optimal Mean Reward", "pub_year": "2018"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:UeHWp8X0CEIC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=13627279711504781089", "cites_id": ["13627279711504781089"]}, "9YcR_ksAAAAJ:kNdYIx-mwKoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Selective Policy Transfer in Multi-Agent Systems with Sparse Interactions", "pub_year": "2024"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:kNdYIx-mwKoC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=6114466022465575835", "cites_id": ["6114466022465575835"]}, "9YcR_ksAAAAJ:7PzlFSSx8tAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Digital Fracture Surface Morphology and Statistical Characteristics of Granite Brazilian Tests after Non-Steady-State Thermal Disturbance", "pub_year": "2024"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:7PzlFSSx8tAC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=17209748723494506000", "cites_id": ["17209748723494506000"]}, "9YcR_ksAAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Leveraging transition exploratory bonus for efficient exploration in Hard-Transiting reinforcement learning problems", "pub_year": "2023"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:LkGwnXOMwfcC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=14966111631761906986", "cites_id": ["14966111631761906986"]}, "9YcR_ksAAAAJ:WF5omc3nYNoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "GUARD: Multigranularity-based Unsupervised Anomaly Detection Algorithm for Multivariate Time Series", "pub_year": "2022"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:WF5omc3nYNoC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=15773964045631306984", "cites_id": ["15773964045631306984"]}, "9YcR_ksAAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Online attentive kernel-based temporal difference learning", "pub_year": "2022"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:Tyk-4Ss8FVUC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=8228984436193654575", "cites_id": ["8228984436193654575"]}, "9YcR_ksAAAAJ:0EnyYjriUFMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning Credit Assignment for Cooperative Reinforcement Learning", "pub_year": "2022"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:0EnyYjriUFMC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=zh-CN&cites=8468853641493602205", "cites_id": ["8468853641493602205"]}, "9YcR_ksAAAAJ:L8Ckcad2t8MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Linear Complementary Dual Codes Constructed from Reinforcement Learning", "pub_year": "2025"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:L8Ckcad2t8MC", "num_citations": 0}, "9YcR_ksAAAAJ:dhFuZR0502QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Beyond Mandatory Federations: Balancing Egoism, Utilitarianism and Egalitarianism in Mixed-Motive Games", "pub_year": "2025"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:dhFuZR0502QC", "num_citations": 0}, "9YcR_ksAAAAJ:QIV2ME_5wuYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Model-Based Offline Reinforcement Learning with Adversarial Data Augmentation", "pub_year": "2025"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:QIV2ME_5wuYC", "num_citations": 0}, "9YcR_ksAAAAJ:9ZlFYXVOiuMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Online Attentive Kernel-Based Off-Policy Temporal Difference Learning", "pub_year": "2024"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:9ZlFYXVOiuMC", "num_citations": 0}, "9YcR_ksAAAAJ:mVmsd5A6BfQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Off-Policy Temporal Difference Learning with Bellman Residuals", "pub_year": "2024"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:mVmsd5A6BfQC", "num_citations": 0}, "9YcR_ksAAAAJ:Wp0gIr-vW9MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A Variance Minimization Approach to Temporal-Difference Learning", "pub_year": "2024"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:Wp0gIr-vW9MC", "num_citations": 0}, "9YcR_ksAAAAJ:qxL8FJ1GzNcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "State Abstraction via Deep Supervised Hash Learning", "pub_year": "2024"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:qxL8FJ1GzNcC", "num_citations": 0}, "9YcR_ksAAAAJ:_kc_bZDykSQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "混合博弈问题的求解与应用综述", "pub_year": "2024"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:_kc_bZDykSQC", "num_citations": 0}, "9YcR_ksAAAAJ:3fE2CSJIrl8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multi-Agent Sparse Interaction Modeling is an Anomaly Detection Problem", "pub_year": "2024"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:3fE2CSJIrl8C", "num_citations": 0}, "9YcR_ksAAAAJ:M3ejUd6NZC8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "STAR: Spatio-Temporal State Compression for Multi-Agent Tasks with Rich Observations", "pub_year": "2024"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:M3ejUd6NZC8C", "num_citations": 0}, "9YcR_ksAAAAJ:4TOpqqG69KYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "基于分组对比学习的序贯感知技能发现方法", "pub_year": "2024"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:4TOpqqG69KYC", "num_citations": 0}, "9YcR_ksAAAAJ:roLk4NBRz8UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Convergence Analysis of Graphical Game-based Nash Q−learning Using the Interaction Detection Signal of N−step Return", "pub_year": "2023"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:roLk4NBRz8UC", "num_citations": 0}, "9YcR_ksAAAAJ:UebtZRa9Y70C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A Survey of Reinforcement Learning Algorithms from a Fixed Point Perspective", "pub_year": "2022"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:UebtZRa9Y70C", "num_citations": 0}, "9YcR_ksAAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Decentralized Counterfactual Value with Threat Detection in Multi-Agent Mixed Cooperative and Competitive Environment"}, "filled": false, "author_pub_id": "9YcR_ksAAAAJ:_FxGoFyzp5QC", "num_citations": 0}}, "citedby5y": 144, "hindex": 6, "hindex5y": 6, "i10index": 6, "i10index5y": 6, "cites_per_year": {"2017": 3, "2018": 6, "2019": 6, "2020": 17, "2021": 12, "2022": 13, "2023": 21, "2024": 41, "2025": 40}, "updated": "2025-06-30 08:27:26.474529"}